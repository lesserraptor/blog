---
layout: post
title: "agentic thinking"
---
i've been using LLMs quite a bit at work lately. our chief product officer is intending to transform the company by incorporating "AI" into our day-to-day work, and so i've been trying to figure out how that will work for me personally.

it's a pretty tall order to expect things to change like that, but the more i've used the LLMs, the more i can see the glint of promise there. there definitely is a benefit here, but it's quite difficult to harness.

as i've considered how i might use this technology, i've somewhat realized that i need to think about "context" and "project knowledge" as something similar to how i've always thought about "data". in other words, i have to think about building the best set of "context" and "project knowledge" i can, and have the LLM's use that to construct the project. i think the ideal here is that you define the context/knowledge base well enough, and the LLM should be able to build the project for you from just that -- similar to how we've always built ETL jobs to manipulate data into a "business value" asset.

to do this, you need to start using "agentic thinking", which i think is mostly a BS term at this point. what it's trying to describe is defining your inputs very clearly, defining your outputs very clearly, and defining whatever context is needed to get you from the inputs to the outputs.

but there are no good blueprints for this yet. no one really knows how to do this yet; similar to the state of the internet back in 1997, you can do some pretty amazing things with this technology, but turning it into something valuable is only glimmers of possibilty right now.

here's some things i've gotten to work that have been clearly valuable:
- list out a road map for a product, and then have it turn that into a visual representation of the roadmap. turning a list into an attractive visual is not easy to do by hand, but the LLM actually makes this simple.
- have the LLM read a github repo and then describe the code to me. i can also have it write functions or utilities that build on ideas in the code. as long as you are asking it to locate things in code and explain them to you, or build something that is "close" to the original code, it actually does a pretty good job.
- take the response to an RFP from a couple vendors and build a document comparing them. reading those RFP responses is a lot of work, and then comparing them even more -- the LLM can speed this up quite nicely.
- locate a moment in a transcript that you can only vaguely describe. for example, "find me the place in this transcript where we asked for more details on process X". searching might not find this easily, but the LLM often can find it.
- take some slop i wrote and re-configure and re-word it to be more convincing. it's remarkably good at this task.

so there's hints that this thing could be powerful, but i haven't yet figured out how to get there all the time. worse, i can't figure out how much of my interactions with the LLM need to be kept, and how much are just junk. i have a constant nagging feeling that i need to "save my work", but i don't know what is actually useful, and i'm also not sure i can ever get the LLM to repeat itself back to the current context. so much here to still learn, but there isn't a "authoritative source" yet, it's mostly just people like me screwing around. 

i guess that's kind of fun for right now, but it's also stupid a lot of the time, and can feel wasteful.
